{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75560ae4-248d-4df6-bc10-342f826e639f",
   "metadata": {},
   "source": [
    "# Anerudh Raina's submission for Perception Assignment by 10xconstruction.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d819db-c939-4480-adc6-5ae8f878e5a6",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "947c8a15-8d10-4c24-87a0-b6b7fc68826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import sqlite3\n",
    "from rosidl_runtime_py.utilities import get_message\n",
    "from rclpy.serialization import deserialize_message\n",
    "import csv\n",
    "from sensor_msgs.msg import Image\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn import linear_model\n",
    "from scipy.spatial import ConvexHull\n",
    "from numpy.linalg import norm\n",
    "import math\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e29bbe5-a83a-487d-b9f0-056341b03871",
   "metadata": {},
   "source": [
    "## Parse rosbag file for messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e1fcc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are  7 messages in  /depth\n"
     ]
    }
   ],
   "source": [
    "def connect(sqlite_file):\n",
    "    conn = sqlite3.connect(sqlite_file)\n",
    "    c = conn.cursor()\n",
    "    return conn, c\n",
    "\n",
    "def close(conn):\n",
    "    conn.close()\n",
    "\n",
    "def countRows(cursor, table_name, print_out=False):\n",
    "    \"\"\" Returns the total number of rows in the database. \"\"\"\n",
    "    cursor.execute('SELECT COUNT(*) FROM {}'.format(table_name))\n",
    "    count = cursor.fetchall()\n",
    "    if print_out:\n",
    "        print('\\nTotal rows: {}'.format(count[0][0]))\n",
    "    return count[0][0]\n",
    "\n",
    "def getHeaders(cursor, table_name, print_out=False):\n",
    "    \"\"\" Returns a list of tuples with column informations:\n",
    "    (id, name, type, notnull, default_value, primary_key)\n",
    "    \"\"\"\n",
    "    # Get headers from table \"table_name\"\n",
    "    cursor.execute('PRAGMA TABLE_INFO({})'.format(table_name))\n",
    "    info = cursor.fetchall()\n",
    "    if print_out:\n",
    "        print(\"\\nColumn Info:\\nID, Name, Type, NotNull, DefaultVal, PrimaryKey\")\n",
    "        for col in info:\n",
    "            print(col)\n",
    "    return info\n",
    "\n",
    "def getAllElements(cursor, table_name, print_out=False):\n",
    "    \"\"\" Returns a dictionary with all elements of the table database.\n",
    "    \"\"\"\n",
    "    # Get elements from table \"table_name\"\n",
    "    cursor.execute('SELECT * from({})'.format(table_name))\n",
    "    records = cursor.fetchall()\n",
    "    if print_out:\n",
    "        print(\"\\nAll elements:\")\n",
    "        for row in records:\n",
    "            print(row)\n",
    "    return records\n",
    "\n",
    "def isTopic(cursor, topic_name, print_out=False):\n",
    "    \"\"\" Returns topic_name header if it exists. If it doesn't, returns empty.\n",
    "        It returns the last topic found with this name.\n",
    "    \"\"\"\n",
    "    boolIsTopic = False\n",
    "    topicFound = []\n",
    "\n",
    "    # Get all records for 'topics'\n",
    "    records = getAllElements(cursor, 'topics', print_out=False)\n",
    "\n",
    "    # Look for specific 'topic_name' in 'records'\n",
    "    for row in records:\n",
    "        if(row[1] == topic_name): # 1 is 'name' TODO\n",
    "            boolIsTopic = True\n",
    "            topicFound = row\n",
    "    if print_out:\n",
    "        if boolIsTopic:\n",
    "             # 1 is 'name', 0 is 'id' TODO\n",
    "            print('\\nTopic named', topicFound[1], ' exists at id ', topicFound[0] ,'\\n')\n",
    "        else:\n",
    "            print('\\nTopic', topic_name ,'could not be found. \\n')\n",
    "\n",
    "    return topicFound\n",
    "\n",
    "def getAllMessagesInTopic(cursor, topic_name, print_out=False):\n",
    "    \"\"\" Returns all timestamps and messages at that topic.\n",
    "    There is no deserialization for the BLOB data.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    timestamps = []\n",
    "    messages = []\n",
    "\n",
    "    # Find if topic exists and its id\n",
    "    topicFound = isTopic(cursor, topic_name, print_out=False)\n",
    "\n",
    "    # If not find return empty\n",
    "    if not topicFound:\n",
    "        print('Topic', topic_name ,'could not be found. \\n')\n",
    "    else:\n",
    "        records = getAllElements(cursor, 'messages', print_out=False)\n",
    "\n",
    "        # Look for message with the same id from the topic\n",
    "        for row in records:\n",
    "            if row[1] == topicFound[0]:     # 1 and 0 is 'topic_id' TODO\n",
    "                count = count + 1           # count messages for this topic\n",
    "                timestamps.append(row[2])   # 2 is for timestamp TODO\n",
    "                messages.append(row[3])     # 3 is for all messages\n",
    "\n",
    "        # Print\n",
    "        if print_out:\n",
    "            print('\\nThere are ', count, 'messages in ', topicFound[1])\n",
    "\n",
    "    return timestamps, messages\n",
    "\n",
    "def getAllTopicsNames(cursor, print_out=False):\n",
    "    \"\"\" Returns all topics names.\n",
    "    \"\"\"\n",
    "    topicNames = []\n",
    "    # Get all records for 'topics'\n",
    "    records = getAllElements(cursor, 'topics', print_out=False)\n",
    "\n",
    "    # Save all topics names\n",
    "    for row in records:\n",
    "        topicNames.append(row[1])  # 1 is for topic name TODO\n",
    "    if print_out:\n",
    "        print('\\nTopics names are:')\n",
    "        print(topicNames)\n",
    "\n",
    "    return topicNames\n",
    "\n",
    "def getAllMsgsTypes(cursor, print_out=False):\n",
    "    \"\"\" Returns all messages types.\n",
    "    \"\"\"\n",
    "    msgsTypes = []\n",
    "    # Get all records for 'topics'\n",
    "    records = getAllElements(cursor, 'topics', print_out=False)\n",
    "\n",
    "    # Save all message types\n",
    "    for row in records:\n",
    "        msgsTypes.append(row[2])  # 2 is for message type TODO\n",
    "    if print_out:\n",
    "        print('\\nMessages types are:')\n",
    "        print(msgsTypes)\n",
    "\n",
    "    return msgsTypes\n",
    "\n",
    "def getMsgType(cursor, topic_name, print_out=False):\n",
    "    \"\"\" Returns the message type of that specific topic.\n",
    "    \"\"\"\n",
    "    msg_type = []\n",
    "    # Get all topics names and all message types\n",
    "    topic_names = getAllTopicsNames(cursor, print_out=False)\n",
    "    msgs_types = getAllMsgsTypes(cursor, print_out=False)\n",
    "\n",
    "    # look for topic at the topic_names list, and find its index\n",
    "    for index, element in enumerate(topic_names):\n",
    "        if element == topic_name:\n",
    "            msg_type = msgs_types[index]\n",
    "    if print_out:\n",
    "        print('\\nMessage type in', topic_name, 'is', msg_type)\n",
    "\n",
    "    return msg_type\n",
    "\n",
    "# path to the bagfile\n",
    "bag_file = 'depth.db3'\n",
    "\n",
    "# topic name\n",
    "topic_name = '/depth'\n",
    "\n",
    "### connect to the database\n",
    "conn, c = connect(bag_file)\n",
    "\n",
    "### get all topics names and types\n",
    "topic_names = getAllTopicsNames(c, print_out=False)\n",
    "topic_types = getAllMsgsTypes(c, print_out=False)\n",
    "\n",
    "# Create a map for quicker lookup\n",
    "type_map = {topic_names[i]:topic_types[i] for i in range(len(topic_types))}\n",
    "\n",
    "### get all timestamps and all messages\n",
    "# t is used as an array of timestamps throughout the code \n",
    "t, msgs = getAllMessagesInTopic(c, topic_name, print_out=True)\n",
    "\n",
    "# Deserialize the message\n",
    "msg_type = get_message(type_map[topic_name])  # Assuming type_map is a dictionary mapping topic names to message types\n",
    "\n",
    "### close connection to the database\n",
    "close(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d5cb86-8c2d-40d4-aa55-d83d4d3fa1ac",
   "metadata": {},
   "source": [
    "## Create dictionary of depth images indexed by the timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b89b24a8-a83f-41e0-96ed-1fde307283e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_img = defaultdict()\n",
    "for timestamp, message in zip(t,msgs):\n",
    "    msg = deserialize_message(message, msg_type)\n",
    "    np_arr = np.frombuffer(msg.data, dtype=np.uint16)\n",
    "    t_img[timestamp] = np_arr.reshape(msg.height, msg.width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7bc88c-b720-41a0-8290-f75feef23736",
   "metadata": {},
   "source": [
    "## Create 3D points from depth map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ef8310b-0713-4614-9791-b888abb272a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_to_3d_points(depth_map, fx=1, fy=1, cx=0, cy=0):\n",
    "    h, w = depth_map.shape\n",
    "    u, v = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    cx, cy = h//2, w//2\n",
    "    # Convert to float for calculations\n",
    "    depth_map = depth_map.astype(np.float32)\n",
    "    \n",
    "    # Handle potential zero depth values (set to a small non-zero value or filter out)\n",
    "    depth_map[depth_map == 0] = np.nan # Or a small value like 0.001\n",
    "\n",
    "    # Handle large depth values (set to a small non-zero value or filter out)\n",
    "    depth_map[depth_map >= 5000] = np.nan \n",
    "\n",
    "    x = (u - cx) * depth_map / fx\n",
    "    y = (v - cy) * depth_map / fy\n",
    "    z = depth_map\n",
    "    \n",
    "    # Stack the coordinates to get (N, 3) array of 3D points\n",
    "    points_3d = np.stack((x, y, z), axis=-1).reshape(-1, 3)\n",
    "    \n",
    "    # Filter out invalid points (e.g., from zero depth or nans)\n",
    "    points_3d = points_3d[~np.isnan(points_3d).any(axis=1)]\n",
    "    return points_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e510638d-116c-45be-bd16-ffb974411fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of 3D points indexed by the timestamp of the frame\n",
    "t_pt = defaultdict()\n",
    "for i in range(len(t)):\n",
    "    t_pt[t[i]] = depth_to_3d_points(t_img[t[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0615ba-500e-404a-be2e-1af93cb3dfa6",
   "metadata": {},
   "source": [
    "## Extract the planes from the 3D points of the scene using RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5056c300-0282-42cb-b082-53fd177fe891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_planes_ransac(points_3d, min_samples=7000, residual_threshold=80.0, max_trials=100):\n",
    "    planes = []\n",
    "    remaining_points = points_3d.copy()\n",
    "    \n",
    "    while len(remaining_points) > min_samples:\n",
    "        model = linear_model.RANSACRegressor(linear_model.LinearRegression(), min_samples=min_samples, residual_threshold=residual_threshold, max_trials=max_trials)\n",
    "        \n",
    "        # Fit a plane (z = ax + by + c)\n",
    "        try:\n",
    "            model.fit(remaining_points[:, :2], remaining_points[:, 2])\n",
    "        except ValueError: # Not enough inliers\n",
    "            break\n",
    "\n",
    "        inlier_mask = model.inlier_mask_\n",
    "        \n",
    "        if np.sum(inlier_mask) < min_samples:\n",
    "            break\n",
    "        \n",
    "        plane_points = remaining_points[inlier_mask]\n",
    "        planes.append(plane_points)\n",
    "        \n",
    "        remaining_points = remaining_points[~inlier_mask]\n",
    "        \n",
    "    return planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcec6f20-b1ea-44d9-ab72-5c7693311f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of planes indexed by the timestamps\n",
    "t_pl = defaultdict()\n",
    "for i in range(len(t)):\n",
    "    t_pl[t[i]] = find_planes_ransac(t_pt[t[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df679ba9-f2e5-4f8b-bb06-730a8c363cbb",
   "metadata": {},
   "source": [
    "## Extract normal vector and visible area of the plane with the greatest area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d249790-be70-4573-8d84-4f582ccceffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to return the normal vector and area of the plane using SVD and Convex Hull\n",
    "def calculate_plane_properties(plane_points):\n",
    "    if len(plane_points) < 3:\n",
    "        return None, None\n",
    "\n",
    "    # Randomly select 10000 points from the plane for efficient \n",
    "    # SVD calculation; this is an approximation\n",
    "    num_rows_to_select = 10000\n",
    "    shuffled_indices = np.random.permutation(plane_points.shape[0])\n",
    "    selected_points = plane_points[shuffled_indices[:num_rows_to_select]]\n",
    "    \n",
    "    # Orientation (Normal Vector)\n",
    "    # Fit a plane to the points: ax + by + cz = d\n",
    "    # This can be done by SVD on the centered points\n",
    "    centroid = np.mean(plane_points, axis=0)\n",
    "    centered_points = selected_points - centroid\n",
    "    _, _, V = np.linalg.svd(centered_points)\n",
    "    normal_vector = V[2, :] # The last column of V is the normal vector\n",
    "    \n",
    "    # Ensure normal points consistently (towards the depth camera, inwards along -Z)\n",
    "    if normal_vector[2] > 0:\n",
    "        normal_vector = -normal_vector\n",
    "\n",
    "    # Surface Area (Approximation using convex hull in 2D projection)\n",
    "    # Project points onto a 2D plane perpendicular to the normal\n",
    "    # This is a simplification; a more accurate area would consider 3D geometry\n",
    "    # For a quick approximation, project onto the dominant 2D plane\n",
    "    if abs(normal_vector[2]) > 0.5: # Mostly horizontal plane\n",
    "        projected_points = plane_points[:, :2]\n",
    "    elif abs(normal_vector[1]) > 0.5: # Mostly vertical along Y\n",
    "        projected_points = plane_points[:, [0, 2]]\n",
    "    else: # Mostly vertical along X\n",
    "        projected_points = plane_points[:, [1, 2]]\n",
    "\n",
    "    if len(projected_points) >= 3:\n",
    "        hull = ConvexHull(projected_points)\n",
    "        surface_area = hull.area\n",
    "    else:\n",
    "        surface_area = 0\n",
    "\n",
    "    return surface_area, normal_vector/norm(normal_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05888c91-b249-4e4f-9cc6-0b615a9a8f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use planes from the timestamps to retrieve normal vector of the plane with the greatest area\n",
    "# and create a dictionary of the retrieved normal vectors indexed with the respective timestamps\n",
    "# Since the task description mentions all units are in SI units, the depth map is presumed to \n",
    "# represent depth in metres\n",
    "t_nv = defaultdict()\n",
    "t_va = defaultdict()\n",
    "\n",
    "for i in range(len(t)):\n",
    "    plane_data = []\n",
    "    for plane_points in t_pl[t[i]]:\n",
    "        area, normal = calculate_plane_properties(plane_points)\n",
    "        if area is not None:\n",
    "            plane_data.append({'area': area, 'normal': normal, 'points': plane_points})\n",
    "    \n",
    "    # Sort the planes by area\n",
    "    sorted_planes = sorted(plane_data, key=lambda x: x['area'], reverse=True)\n",
    "\n",
    "    # Assign the plane with the highest area to the dictionary\n",
    "    t_nv[t[i]] = sorted_planes[0]['normal']\n",
    "    t_va[t[i]] = sorted_planes[0]['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9222cdaf-2cfd-4e12-ab7d-47c8e0dd46b4",
   "metadata": {},
   "source": [
    "## Calculate the angle between the normal vector of the plane with the greatest area and the camera normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "987a11c6-9d02-44ef-8c41-f600c6bb30df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the angle, in radians, between the normal vector and the camera normal\n",
    "def calculate_angle_to_camera_normal(plane_vector):\n",
    "    # Set the camera normal following the illustration in the project description\n",
    "    camera_normal = np.array([0, 0, -1])\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    cosine = np.dot(plane_vector, camera_normal) / (norm(plane_vector) * norm(camera_normal))\n",
    "    \n",
    "    # Compute the angle\n",
    "    angle = math.acos(cosine)\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "078f5828-e728-4bfa-a47a-867c2110ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of the normal angle indexed with the timestamp from the normal vectors\n",
    "t_na = defaultdict()\n",
    "for i in range(len(t)):\n",
    "    t_na[t[i]] = calculate_angle_to_camera_normal(t_nv[t[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db91d9e-0454-416b-b2c8-f665ad53477e",
   "metadata": {},
   "source": [
    "## Calculate the axis of rotation and put them into dictionaries indexed by the timestamps between contiguous frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2c022e66-332c-44e6-a72c-7161830b1da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of the rotation axis indexed by the respective timestamp\n",
    "t_rotax = defaultdict()\n",
    "\n",
    "for i in range(1,len(t)):\n",
    "    # Calculate the cross product of contiguous normal vectors, which gives us the axis of rotation\n",
    "    axis = np.cross(t_nv[t[i-1]], t_nv[t[i]])\n",
    "    t_rotax[t[i]] = axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "df657f8d-438a-47af-9955-5614b2a9a2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axis of rotation is: [ 9.42041013e-04  2.14159447e-04 -1.31697941e-06], between timestamp: 1702944981696402893 and 1702944983557733535\n",
      "Axis of rotation is: [ 1.34754913e-03 -6.92822840e-04 -4.48732807e-08], between timestamp: 1702944983557733535 and 1702944985025921707\n",
      "Axis of rotation is: [ 4.38314953e-04  8.19202224e-05 -1.66077641e-07], between timestamp: 1702944985025921707 and 1702944985759606745\n",
      "Axis of rotation is: [ 8.65058373e-04  2.27908217e-04 -3.31391762e-07], between timestamp: 1702944985759606745 and 1702944986493891910\n",
      "Axis of rotation is: [-2.72359322e-03  4.87245307e-04  2.01972726e-06], between timestamp: 1702944986493891910 and 1702944989365535811\n",
      "Axis of rotation is: [-2.62182490e-04 -1.80787001e-04  6.30047390e-07], between timestamp: 1702944989365535811 and 1702944992368860933\n"
     ]
    }
   ],
   "source": [
    "# Print axis of rotation for the contiguous timestamps\n",
    "for i in range(1,len(t)):\n",
    "    print('Axis of rotation is: '+ str( t_rotax[t[i]]) + ', between timestamp: '+str(t[i-1])+' and '+str(t[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c6557ef1-33a5-4b86-8e52-9cb12182011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For frame number: 0, normal vector is:[-7.65422416e-04 -2.78257450e-03 -9.99995836e-01],\n",
      "visible area: 5125935.406565146 sq.m., for the timestamp: 1702944981696402893\n",
      "For frame number: 1, normal vector is:[-9.79584278e-04 -1.84053510e-03 -9.99997826e-01],\n",
      "visible area: 3569325.594002464 sq.m., for the timestamp: 1702944983557733535\n",
      "For frame number: 2, normal vector is:[-2.86761902e-04 -4.92986747e-04 -9.99999837e-01],\n",
      "visible area: 2347281.299395097 sq.m., for the timestamp: 1702944985025921707\n",
      "For frame number: 3, normal vector is:[-3.68682165e-04 -5.46717682e-05 -9.99999931e-01],\n",
      "visible area: 2183704.337621796 sq.m., for the timestamp: 1702944985759606745\n",
      "For frame number: 4, normal vector is:[-5.96590237e-04  8.10386689e-04 -9.99999494e-01],\n",
      "visible area: 1882734.9014734945 sq.m., for the timestamp: 1702944986493891910\n",
      "For frame number: 5, normal vector is:[-0.00108383 -0.00191321 -0.99999758],\n",
      "visible area: 3370265.014459785 sq.m., for the timestamp: 1702944989365535811\n",
      "For frame number: 6, normal vector is:[-9.03046826e-04 -2.17539190e-03 -9.99997226e-01],\n",
      "visible area: 3100073.888696685 sq.m., for the timestamp: 1702944992368860933\n"
     ]
    }
   ],
   "source": [
    "# Print normal vector and area of the plane with the greatest area for the timestamp and frame number\n",
    "for i in range(len(t)):\n",
    "    print('For frame number: '+str(i)+', normal vector is:'+str(t_nv[t[i]])+',\\nvisible area: '+str(t_va[t[i]])+' sq.m., for the timestamp: '+str(t[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9833a835-c076-4425-a555-4897e095ea12",
   "metadata": {},
   "source": [
    "## Create the table and text file and write to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f87533eb-c1dd-4a79-96a2-5ea50201d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the CSV file for writing table normal angle and visible area\n",
    "csv_file_path = 'table_normal_angle_visible_area.csv'\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    # Create a CSV writer\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    for i in range(len(t)):\n",
    "            # To the csv table, write the frame number, normal vector, visible area, and timestamp \n",
    "            csv_writer.writerow([str(i),str(t_nv[t[i]]),str(t_va[t[i]]),t[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "64ed5b22-d10e-4e64-a953-6218f9e39bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the text file for writing the axis of rotation with the timestamps it is calculated between\n",
    "axes = np.array(['X', 'Y', 'Z'])\n",
    "txt_file_name = 'rotation_axis.txt'\n",
    "with open(txt_file_name, \"w\") as file:\n",
    "    for i in range(1, len(t)):\n",
    "        max_val = max(abs(t_rotax[t[i]]))\n",
    "        index = np.where(abs(t_rotax[t[i]])==max_val)\n",
    "        file.write('Major axis of rotation is: '+str(axes[index][0]) + ', with rotation vector: ' + str( t_rotax[t[i]]) + ', between timestamps: '+str(t[i-1])+' and '+str(t[i])+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f5948-a227-46f7-bdef-84923a514673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201077ea-84c1-42b1-8522-3ed9f6c517e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf0f4e0-6f92-4db1-84fa-f5fd5673fdf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
